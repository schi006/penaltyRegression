---
title: "tutorial"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# penaltyRegression

## Overview
`penaltyRegression` implements linear regression, ridge regression and lasso in c++ using Armadillo.
1.linear_fit: fit linear regression and return beta, fitted value, residual
2.ridge_fit: fit ridge regression and return beta, fitted value, residual
3.lasso_fit: fit lasso regression and return beta, fitted value, residual

## Example
```{r}
library(penaltyRegression)

###linear regression

#### simulate data
set.seed(0)
x <- matrix(runif(50), ncol = 1)
y <- matrix(2*x[,1] + rnorm(50,mean = 0, sd=0.1), ncol = 1)
res_linear = linear_fit(x,y) #fit linear regression
res_linear$beta  #coefficients
res_linear$fit
res_linear$residual
reg_plot(x, y, res_linear$beta)
res_plot(res_linear$residual, res_linear$fit)

#### compare with R function
v1=lm(y~x-1)$coef
v2=res_linear$beta

#correctness
all.equal(unname(v1),as.numeric(v2))
#efficiency
effi <- bench::mark(penaltyRegression = linear_fit(x,y),lm = lm(y~x-1), check = F)
effi
plot(effi)


###ridge regression

#### simulate data
set.seed(0)
x <- matrix(runif(100), ncol = 2)
y <- matrix(2*x[,1] + 3*x[,2] + rnorm(50,mean = 0, sd=0.1), ncol = 1)
lambda=0.001
res_ridge = ridge_fit(x,y,lambda)
res_ridge$beta  #coefficients
res_ridge$fit
res_ridge$residual
reg_plot(x, y, res_ridge$beta)
res_plot(res_ridge$residual, res_ridge$fit)

#### compare with R function
require(MASS)
require(glmnet)
v2=lm.ridge(y~x-1, Inter = FALSE, lambda=lambda)$coef
v3=glmnet(x, y, alpha = 0, lambda = lambda, intercept = FALSE)$beta
v1=res_ridge$beta  

#correctness
all.equal(as.numeric(v1),as.numeric(v2),as.numeric(v3))
#efficiency
effi <- bench::mark(penaltyRegression = ridge_fit(x, y, lambda=lambda),glmnet = glmnet(x, y, alpha = 0, lambda = lambda, intercept = FALSE), MASS=lm.ridge(y~x-1, Inter = FALSE, lambda=lambda),check = F)
effi
plot(effi)


### lasso regression

#### simulate data
set.seed(0)
x <- matrix(runif(100), ncol = 2)
y <- matrix(2*x[,1] + 3*x[,2] + rnorm(50,mean = 0, sd=0.1), ncol = 1)

res_lasso = lasso_fit(x, y, lambda=lambda, tol = 1e-10,max_iter = 10000)
res_lasso$beta #coefficients
res_lasso$fit #fitted value
res_lasso$residual

#### compare with R function
require(glmnet)
v2=glmnet(x, y, alpha = 1, lambda = lambda, intercept = FALSE)$beta
v1=res_lasso$beta

#correctness
all.equal(as.numeric(v1),as.numeric(v2),tolerance=1e-3) #might have slightly difference due to different tolerance and maximum iterations setting in two function
#efficiency
effi <- bench::mark(penaltyRegression = lasso_fit(x, y, lambda=lambda, tol = 1e-10,max_iter = 10000),glmnet = glmnet(x, y, alpha = 1, lambda = lambda, intercept = FALSE), check = F)
effi
plot(effi)
```

